{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3ab75d",
   "metadata": {},
   "source": [
    "# Dataset Processing \n",
    "Process the datasets for the MOCA dataset (blood and neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scvelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bbb31",
   "metadata": {},
   "source": [
    "## Further Exploration with Embryonic Dataset - Blood (and Neuron later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15af0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from scipy.io import mmread\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Purpose: Verify the matrices and counts for the trajectory chosen\n",
    "Params: dataset name (blood or neurons)\n",
    "Return: introns, extrons, var, obs\n",
    "\"\"\"\n",
    "def verify_trajectory(dataset): \n",
    "\n",
    "    #1. Load matrices ( cells x genes)\n",
    "    print(\"\\nLoading count matrices:\")\n",
    "    exon = mmread(f\"{dataset}/exp_exon.mtx\").tocsr()\n",
    "    intron = mmread(f\"{dataset}/exp_intron.mtx\").tocsr()\n",
    "    print(f\"Spliced: {exon.shape}\")\n",
    "    print(f\"Unspliced: {intron.shape}\")\n",
    "\n",
    "    #2. Load cell metadata\n",
    "    print(\"\\nLoading cell metadata:\")\n",
    "    obs = pd.read_csv(f\"{dataset}/obs.csv\", index_col=0)\n",
    "    print(f\"Cells: {len(obs):,}\")\n",
    "    print(f\"Columns: {list(obs.columns)}\")\n",
    "\n",
    "    #3. Load gene metadata\n",
    "    print(\"\\nLoading gene metadata:\")\n",
    "    var = pd.read_csv(\"E9.5_to_E13.5_var.csv\", index_col=0) #same gene file across \n",
    "    print(f\"Genes: {len(var):,}\")\n",
    "\n",
    "    #4. Verify alignment\n",
    "    print(\"\\nVerify the dimensions dimensions:\")\n",
    "    assert exon.shape[0] == len(obs), f\"Cell mismatch: {exon.shape[0]} vs {len(obs)}\"\n",
    "    assert exon.shape[1] == len(var), f\"Gene mismatch: {exon.shape[1]} vs {len(var)}\"\n",
    "    print(\"All dimensions aligned!\")\n",
    "\n",
    "    return intron, exon, var, obs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5662be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: Convert trajectory information into adata\n",
    "Params: intron, extron, var, obs files\n",
    "Return: adata object\n",
    "\"\"\"\n",
    "\n",
    "def convert_trajectory(intron, exon, var, obs):\n",
    "    # Get the adata file for easy access\n",
    "    adata = sc.AnnData(X=(exon + intron).tocsr())\n",
    "\n",
    "    # Add cell metadata\n",
    "    adata.obs = obs.copy()\n",
    "    adata.obs_names = obs.index.astype(str)\n",
    "\n",
    "    # Add gene metadata  \n",
    "    adata.var = var.copy()\n",
    "    adata.var_names = var['gene_short_name'].values\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    # Add spliced/unspliced layers for velocity\n",
    "    adata.layers['spliced'] = exon\n",
    "    adata.layers['unspliced'] = intron\n",
    "\n",
    "\n",
    "    # Get numeric timepoint from 'day' column\n",
    "    adata.obs['timepoint_str'] = adata.obs['day'].astype(str)\n",
    "    adata.obs['timepoint'] = (\n",
    "        adata.obs['day']\n",
    "        .str.replace('E', '', regex=False)\n",
    "        .str.replace('b', '', regex=False)  # Handle E8.5b -> 8.5\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: Summarize and save data\n",
    "Params: adata object, dataset name\n",
    "Return: None\n",
    "\"\"\"\n",
    "def save_adata(adata, dataset):\n",
    "    # Print final summary\n",
    "    print(\"\\nFINAL ANNDATA SUMMARY\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Cells: {adata.n_obs:,}\")\n",
    "    print(f\"Genes: {adata.n_vars:,}\")\n",
    "    print(f\"Layers: {list(adata.layers.keys())}\")\n",
    "    print(f\"Obs cols: {list(adata.obs.columns)}\")\n",
    "\n",
    "    print(f\"\\nTimepoints:\")\n",
    "    print(adata.obs['timepoint'].value_counts().sort_index())\n",
    "\n",
    "    print(f\"\\nCell types:\")\n",
    "    print(adata.obs['celltype'].value_counts())\n",
    "\n",
    "    # Save file\n",
    "    adata.write(f\"{dataset}/{dataset}_data.h5ad\")\n",
    "    print(f\"Saved: {dataset}/{dataset}_data.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49b21b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: create and save file adata file!\n",
    "Params: dataset name\n",
    "Return: None\n",
    "\"\"\"\n",
    "def create_adata(dataset):\n",
    "    intron, extron, var, obs = verify_trajectory(dataset)\n",
    "    adata = convert_trajectory(intron, extron, var, obs)\n",
    "    save_adata(adata, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7131991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading count matrices:\n",
      "Spliced: (53268, 24552)\n",
      "Unspliced: (53268, 24552)\n",
      "\n",
      "Loading cell metadata:\n",
      "Cells: 53,268\n",
      "Columns: ['Anno', 'day', 'celltype', 'sample', 'batch', 'group']\n",
      "\n",
      "Loading gene metadata:\n",
      "Genes: 24,552\n",
      "\n",
      "Verify the dimensions dimensions:\n",
      "All dimensions aligned!\n",
      "\n",
      "FINAL ANNDATA SUMMARY\n",
      "--------------------------------------------------\n",
      "Cells: 53,268\n",
      "Genes: 24,552\n",
      "Layers: ['spliced', 'unspliced']\n",
      "Obs cols: ['Anno', 'day', 'celltype', 'sample', 'batch', 'group', 'timepoint_str', 'timepoint']\n",
      "\n",
      "Timepoints:\n",
      "timepoint\n",
      "8.5      2877\n",
      "9.5      3390\n",
      "10.5     9308\n",
      "11.5    14930\n",
      "12.5     9090\n",
      "13.5    13673\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cell types:\n",
      "celltype\n",
      "Definitive erythroid cells    22038\n",
      "Primitive erythroid cells     21309\n",
      "White blood cells              8213\n",
      "Megakaryocytes                 1509\n",
      "Blood progenitors               199\n",
      "Name: count, dtype: int64\n",
      "Saved: blood/blood_data.h5ad\n"
     ]
    }
   ],
   "source": [
    "# blood files\n",
    "create_adata('blood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8b3d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading count matrices:\n",
      "Spliced: (141576, 24552)\n",
      "Unspliced: (141576, 24552)\n",
      "\n",
      "Loading cell metadata:\n",
      "Cells: 141,576\n",
      "Columns: ['Anno', 'day', 'celltype', 'sample', 'batch', 'group', 'ID']\n",
      "\n",
      "Loading gene metadata:\n",
      "Genes: 24,552\n",
      "\n",
      "Verify the dimensions dimensions:\n",
      "All dimensions aligned!\n",
      "\n",
      "FINAL ANNDATA SUMMARY\n",
      "--------------------------------------------------\n",
      "Cells: 141,576\n",
      "Genes: 24,552\n",
      "Layers: ['spliced', 'unspliced']\n",
      "Obs cols: ['Anno', 'day', 'celltype', 'sample', 'batch', 'group', 'ID', 'timepoint_str', 'timepoint']\n",
      "\n",
      "Timepoints:\n",
      "timepoint\n",
      "8.5      5000\n",
      "9.5      3254\n",
      "10.5    23205\n",
      "11.5    39737\n",
      "12.5    36687\n",
      "13.5    33693\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cell types:\n",
      "celltype\n",
      "Spinal cord excitatory neurons         20000\n",
      "Neuron progenitor cells                18855\n",
      "Spinal cord inhibitory neurons         17477\n",
      "Inhibitory interneurons                16864\n",
      "Intermediate progenitor cells          16386\n",
      "Di/mesencephalon excitatory neurons    16258\n",
      "Di/mesencephalon inhibitory neurons    14571\n",
      "Motor neurons                          13656\n",
      "Forebrain/midbrain                      5000\n",
      "Noradrenergic neurons                   2509\n",
      "Name: count, dtype: int64\n",
      "Saved: neuron/neuron_data.h5ad\n"
     ]
    }
   ],
   "source": [
    "# neuron files\n",
    "create_adata('neuron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3504fec",
   "metadata": {},
   "source": [
    "## Explore Mouse Gastriculation\n",
    "Taken from the scVelo Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032500cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "\n",
    "adata = scv.datasets.gastrulation()\n",
    "\n",
    "print(\"OBS columns:\")\n",
    "print(adata.obs.columns.tolist())\n",
    "\n",
    "print(\"VAR columns:\")\n",
    "print(adata.var.columns.tolist())\n",
    "\n",
    "print(\"Layers:\", adata.layers.keys())\n",
    "\n",
    "adata.X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the timepoint from the stage column\n",
    "adata.obs[\"timepoint\"] = adata.obs[\"stage\"]\n",
    "print(adata.obs[\"stage\"].unique())\n",
    "print(adata.obs[\"timepoint\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "adata.write(\"mouse_data.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bb25b",
   "metadata": {},
   "source": [
    "## Graph Creation\n",
    "Take adata and convert it to a pytorch graph. Initially do cosine similarity between gene expression for the edge weights. Will re-weight with scVelo RNA velocity down the line. Let timepoints be node features as well as gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster torch-spline-conv -y\n",
    "%pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python -c \"import torch; print(torch.__version__)\"\n",
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ecd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch-geometric\n",
    "%pip install scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"numpy<2\"\n",
    "%pip install scanpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c18099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "import scipy.sparse as sp\n",
    "import scanpy as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef344225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: create the graph as a pytorch graph and save \n",
    "Params: dataset name, adata object, preprocessing params\n",
    "Return: None\n",
    "\"\"\"\n",
    "\n",
    "def create_graph(dataset, adata, n_neighbors=15, n_comps=50, n_pcs=50, n_top_genes=2000):\n",
    "\n",
    "    \"\"\"Data preprocessing for PCA\"\"\"\n",
    "    # Standard filtering and normalization\n",
    "    sc.pp.filter_genes(adata, min_cells=10)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)\n",
    "    print(f\"Highly variable genes: {adata.var['highly_variable'].sum()}\")\n",
    "\n",
    "    # Prevent densification issue\n",
    "    adata = adata[:, adata.var[\"highly_variable\"]].copy()\n",
    "    \n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "    sc.tl.pca(adata, n_comps=n_comps)\n",
    "    expr_pca = adata.obsm['X_pca']  # [n_cells, 50]\n",
    "    print(f\"PCA shape: {expr_pca.shape}\")\n",
    "    \n",
    "    \"\"\"Adding Node Features\"\"\"\n",
    "    x = torch.tensor(expr_pca, dtype=torch.float32)\n",
    "    print(f\"Node features: {x.shape[1]} (PCA components)\")\n",
    "    \n",
    "    # Timepoint as separate attribute\n",
    "    if adata.obs['timepoint'].dtype == 'object' or adata.obs['timepoint'].dtype.name == 'category':\n",
    "        # Convert \"E8.5\" to 8.5\n",
    "        timepoints = adata.obs['timepoint'].astype(str).str.replace('E', '').astype(float)\n",
    "    else:\n",
    "        timepoints = adata.obs['timepoint'].values\n",
    "    timepoints_norm = (timepoints - timepoints.mean()) / timepoints.std()\n",
    "    print(f\"Timepoints: {np.unique(timepoints)}\")\n",
    "    print(f\"Normalized Timepoints: {np.unique(timepoints_norm)}\")\n",
    "    \n",
    "    \"\"\"Adding Edges\"\"\"\n",
    "    # Compute neighbors w/ PCA\n",
    "    print(\"Calculating the neighbors with PCA\")\n",
    "    sc.pp.neighbors(adata, n_neighbors=n_neighbors, use_rep='X_pca') \n",
    "    connectivities = adata.obsp['connectivities']\n",
    "    rows, cols = connectivities.nonzero()\n",
    "    \n",
    "    # cosine similarity on PCA embeddings (vectorized for speed)\n",
    "    print(\"Running cosine similarity on neighbors\")\n",
    "    source_embeddings = expr_pca[rows]  # [n_edges, 50]\n",
    "    target_embeddings = expr_pca[cols]  # [n_edges, 50]\n",
    "    \n",
    "    # Compute all similarities at once\n",
    "    edge_weights = np.sum(source_embeddings * target_embeddings, axis=1) / (\n",
    "        np.linalg.norm(source_embeddings, axis=1) * np.linalg.norm(target_embeddings, axis=1) + 1e-8\n",
    "    )\n",
    "    \n",
    "    edge_index = torch.tensor(np.vstack([rows, cols]), dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edge_weights, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    print(f\"Edges: {edge_index.shape[1]:,}\")\n",
    "    print(f\"Edge weights: [{edge_weights.min():.3f}, {edge_weights.max():.3f}]\")\n",
    "    \n",
    "    \"\"\"Adding Metadata (Cell Labels)\"\"\"\n",
    "    celltype_cat = adata.obs['celltype'].astype('category')\n",
    "    celltype_codes = torch.tensor(celltype_cat.cat.codes.values, dtype=torch.long)\n",
    "    celltype_names = list(celltype_cat.cat.categories)\n",
    "    print(f\"Cell types: {len(celltype_names)}\")\n",
    "    \n",
    "    \"\"\"Create Graph\"\"\"\n",
    "    graph = Data(\n",
    "        x=x,                              # [n_cells, 50] PCA embeddings\n",
    "        edge_index=edge_index,            # [2, n_edges]\n",
    "        edge_attr=edge_attr,              # [n_edges, 1] cosine similarity\n",
    "        timepoint=timepoints,             # [n_cells] raw timepoint\n",
    "        timepoint_norm=timepoints_norm,   # [n_cells] normalized timepoint\n",
    "        celltype=celltype_codes,          # [n_cells] integer cell type labels\n",
    "    )\n",
    "    \n",
    "    # Store metadata (not tensors)\n",
    "    graph.celltype_names = celltype_names\n",
    "    graph.n_cells = adata.n_obs\n",
    "    graph.n_pcs = n_comps\n",
    "    \n",
    "    print(\"Graph created:\", graph)\n",
    "    \n",
    "    # Save graph as pytorch graph and rewrite adata\n",
    "    torch.save(graph, f\"{dataset}/{dataset}_graph.pt\")\n",
    "    print(f\"Saved graph to {dataset}/{dataset}_graph.pt\")\n",
    "    \n",
    "    adata.write(f\"{dataset}/{dataset}_data.h5ad\")\n",
    "    print(f\"Updated .h5ad file {dataset}/{dataset}_data.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f707d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 53,268 cells and 24,552 genes\n",
      "Highly variable genes: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/functools.py:909: UserWarning: zero-centering a sparse array/matrix densifies it.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA shape: (53268, 50)\n",
      "Node features: 50 (PCA components)\n",
      "Timepoints: [ 8.5  9.5 10.5 11.5 12.5 13.5]\n",
      "Normalized Timepoints: [-2.24107041 -1.54507785 -0.8490853  -0.15309275  0.5428998   1.23889235]\n",
      "Calculating the neighbors with PCA\n",
      "Running cosine similarity on neighbors\n",
      "Edges: 1,343,922\n",
      "Edge weights: [0.127, 0.989]\n",
      "Cell types: 5\n",
      "Graph created: Data(x=[53268, 50], edge_index=[2, 1343922], edge_attr=[1343922, 1], timepoint=[53268], timepoint_norm=[53268], celltype=[53268], celltype_names=[5], n_cells=53268, n_pcs=50)\n",
      "Saved graph to blood/blood_graph.pt\n",
      "Updated .h5ad file blood/blood_data.h5ad\n"
     ]
    }
   ],
   "source": [
    "# Load the adata BLOOD\n",
    "adata = sc.read_h5ad(\"blood/blood_data.h5ad\")\n",
    "print(f\"Loaded: {adata.n_obs:,} cells and {adata.n_vars:,} genes\")\n",
    "\n",
    "create_graph('blood',adata, n_neighbors=15, n_comps=50, n_pcs=50, n_top_genes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d678ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 141,576 cells and 24,552 genes\n",
      "Highly variable genes: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/functools.py:909: UserWarning: zero-centering a sparse array/matrix densifies it.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA shape: (141576, 50)\n",
      "Node features: 50 (PCA components)\n",
      "Timepoints: [ 8.5  9.5 10.5 11.5 12.5 13.5]\n",
      "Normalized Timepoints: [-2.69563266 -1.90727003 -1.1189074  -0.33054477  0.45781787  1.2461805 ]\n",
      "Calculating the neighbors with PCA\n",
      "Running cosine similarity on neighbors\n",
      "Edges: 3,294,318\n",
      "Edge weights: [0.112, 0.983]\n",
      "Cell types: 10\n",
      "Graph created: Data(x=[141576, 50], edge_index=[2, 3294318], edge_attr=[3294318, 1], timepoint=[141576], timepoint_norm=[141576], celltype=[141576], celltype_names=[10], n_cells=141576, n_pcs=50)\n",
      "Saved graph to neuron/neuron_graph.pt\n",
      "Updated .h5ad file neuron/neuron_data.h5ad\n"
     ]
    }
   ],
   "source": [
    "# Load the adata NEURON\n",
    "adata = sc.read_h5ad(\"neuron/neuron_data.h5ad\")\n",
    "print(f\"Loaded: {adata.n_obs:,} cells and {adata.n_vars:,} genes\")\n",
    "\n",
    "create_graph('neuron',adata, n_neighbors=15, n_comps=50, n_pcs=50, n_top_genes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afaa817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 89,267 cells and 53,801 genes\n",
      "Highly variable genes: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/functools.py:909: UserWarning: zero-centering a sparse array/matrix densifies it.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA shape: (89267, 50)\n",
      "Node features: 50 (PCA components)\n",
      "Timepoints: [6.5  7.5  6.75 7.75 7.   8.   8.5  7.25 8.25]\n",
      "Normalized Timepoints: [-2.25657996 -0.49925956 -1.81724986 -0.05992945 -1.37791976  0.37940065\n",
      "  1.25806085 -0.93858966  0.81873075]\n",
      "Calculating the neighbors with PCA\n",
      "Running cosine similarity on neighbors\n",
      "Edges: 1,961,242\n",
      "Edge weights: [0.223, 0.998]\n",
      "Cell types: 34\n",
      "Graph created: Data(x=[89267, 50], edge_index=[2, 1961242], edge_attr=[1961242, 1], timepoint=index\n",
      "cell_1         6.5\n",
      "cell_2         6.5\n",
      "cell_6         6.5\n",
      "cell_8         6.5\n",
      "cell_9         6.5\n",
      "              ... \n",
      "cell_139326    8.5\n",
      "cell_139327    8.5\n",
      "cell_139329    8.5\n",
      "cell_139330    8.5\n",
      "cell_139331    8.5\n",
      "Name: timepoint, Length: 89267, dtype: float64, timepoint_norm=index\n",
      "cell_1        -2.256580\n",
      "cell_2        -2.256580\n",
      "cell_6        -2.256580\n",
      "cell_8        -2.256580\n",
      "cell_9        -2.256580\n",
      "                 ...   \n",
      "cell_139326    1.258061\n",
      "cell_139327    1.258061\n",
      "cell_139329    1.258061\n",
      "cell_139330    1.258061\n",
      "cell_139331    1.258061\n",
      "Name: timepoint, Length: 89267, dtype: float64, celltype=[89267], celltype_names=[34], n_cells=89267, n_pcs=50)\n",
      "Saved graph to mouse/mouse_graph.pt\n",
      "Updated .h5ad file mouse/mouse_data.h5ad\n"
     ]
    }
   ],
   "source": [
    "# Load the adata for the mouse dataset\n",
    "adata = sc.read_h5ad(\"mouse/mouse_data.h5ad\")\n",
    "print(f\"Loaded: {adata.n_obs:,} cells and {adata.n_vars:,} genes\")\n",
    "\n",
    "create_graph('mouse', adata, n_neighbors=15, n_comps=50, n_pcs=50, n_top_genes=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf8c86",
   "metadata": {},
   "source": [
    "## Reweight the edges\n",
    "Use scVelo and the equation cosine_w + alpha * cosine_similarity(distance between cells, RNA velocity). This should downweight cells not in the direction of the RNA velocity, while upweighting those that are closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scvelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24c60510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "Purpose: Compute RNA velocity using scVelo\n",
    "Params: adata object, preprocessing parameters\n",
    "Return: adata with velocity computed\n",
    "\"\"\"\n",
    "def compute_velocity(adata, min_shared_counts=20, n_top_genes=2000, n_pcs=50, n_neighbors=15):\n",
    "    print(\"COMPUTING RNA VELOCITY\")\n",
    "    \n",
    "    # scVelo preprocessing\n",
    "    print(\"\\nPreprocessing for velocity!\")\n",
    "    scv.pp.filter_and_normalize(adata, min_shared_counts=min_shared_counts, n_top_genes=n_top_genes)\n",
    "    scv.pp.moments(adata, n_pcs=n_pcs, n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Compute velocity\n",
    "    print(\"\\nComputing velocity!\")\n",
    "    scv.tl.velocity(adata, mode='stochastic')\n",
    "    \n",
    "    # Build velocity graph\n",
    "    print(\"\\nBuilding velocity graph!\")\n",
    "    scv.tl.velocity_graph(adata)\n",
    "    \n",
    "    # Get the velocity in gene space\n",
    "    velocity_genes = adata.layers['velocity']\n",
    "    \n",
    "    # Get the PCA loadings (genes x PCs)\n",
    "    pca_loadings = adata.varm['PCs']  # [n_genes, n_pcs]\n",
    "    \n",
    "    # Project: velocity_pca = velocity_genes @ pca_loadings\n",
    "    # Handle sparse matrix if needed\n",
    "    if hasattr(velocity_genes, 'toarray'):\n",
    "        velocity_genes = velocity_genes.toarray()\n",
    "    \n",
    "    # Replace NaNs with 0 (some genes have no velocity)\n",
    "    velocity_genes = np.nan_to_num(velocity_genes, nan=0.0)\n",
    "    \n",
    "    velocity_pca = velocity_genes @ pca_loadings\n",
    "    adata.obsm['velocity_pca'] = velocity_pca\n",
    "    \n",
    "    print(f\"\\nVelocity computed!\")\n",
    "    print(f\"  Velocity (genes): {adata.layers['velocity'].shape}\")\n",
    "    print(f\"  Velocity (PCA):   {velocity_pca.shape}\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: Reweight graph edges using velocity alignment\n",
    "Params: graph object, adata with velocity, alpha hyperparameter\n",
    "Return: graph with updated edge weights\n",
    "\"\"\"\n",
    "def reweight_edges(graph, adata, alpha=0.5):\n",
    "    print(\"REWEIGHTING EDGES WITH VELOCITY\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get velocity in PCA space\n",
    "    velocity_pca = adata.obsm['velocity_pca']\n",
    "    \n",
    "    # Get graph data as numpy\n",
    "    x = graph.x.numpy()\n",
    "    edge_index = graph.edge_index.numpy()\n",
    "    w_cosine = graph.edge_attr.numpy().flatten()\n",
    "    \n",
    "    print(f\"\\nAlpha: {alpha}\")\n",
    "    print(f\"Edges: {edge_index.shape[1]:,}\")\n",
    "    print(\"Computing velocity alignment\")\n",
    "    \n",
    "    rows = edge_index[0]\n",
    "    cols = edge_index[1]\n",
    "    alignments = np.zeros(edge_index.shape[1])\n",
    "    \n",
    "    v_i = velocity_pca[rows]             # [E, d]\n",
    "    d_ij = x[cols] - x[rows]             # [E, d]\n",
    "\n",
    "    # dot products for ALL edges\n",
    "    dots = np.sum(v_i * d_ij, axis=1)\n",
    "\n",
    "    # norms\n",
    "    norm_v = np.linalg.norm(v_i, axis=1)\n",
    "    norm_d = np.linalg.norm(d_ij, axis=1)\n",
    "\n",
    "    # cosine between velocity and displacement\n",
    "    alignments = dots / (norm_v * norm_d + 1e-8)\n",
    "    \n",
    "    # Compute new weights\n",
    "    w_new = (1 - alpha) * w_cosine + alpha * alignments\n",
    "    \n",
    "    # Print stats\n",
    "    print(f\"\\nAlignment stats:\")\n",
    "    print(f\"  Range: [{alignments.min():.3f}, {alignments.max():.3f}]\")\n",
    "    print(f\"  Mean:  {alignments.mean():.3f}\")\n",
    "    \n",
    "    print(f\"\\nEdge weight stats:\")\n",
    "    print(f\"  Before: [{w_cosine.min():.3f}, {w_cosine.max():.3f}]\")\n",
    "    print(f\"  After:  [{w_new.min():.3f}, {w_new.max():.3f}]\")\n",
    "    \n",
    "    # Update graph\n",
    "    graph.edge_attr = torch.tensor(w_new, dtype=torch.float32).unsqueeze(1)\n",
    "    graph.velocity_alignment = torch.tensor(alignments, dtype=torch.float32)\n",
    "    \n",
    "    print(f\"\\nEdges reweighted!\")\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: Save velocity adata and reweighted graph\n",
    "Params: adata, graph, dataset name\n",
    "Return: None\n",
    "\"\"\"\n",
    "def save_velocity_data(adata, graph, dataset):\n",
    "    print(\"\\nSAVING NOW\")\n",
    "    \n",
    "    adata.write(f\"{dataset}/{dataset}_velocity_data.h5ad\")\n",
    "    print(f\"Saved: {dataset}/{dataset}_velocity_data.h5ad\")\n",
    "    \n",
    "    torch.save(graph, f\"{dataset}/{dataset}_graph_velocity.pt\")\n",
    "    print(f\"Saved: {dataset}/{dataset}_graph_velocity.pt\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: Full pipeline to compute velocity and reweight graph\n",
    "Params: adata, dataset name, alpha, preprocessing params\n",
    "Return: adata, graph (both updated)\n",
    "\"\"\"\n",
    "def velocity_pipeline(adata, dataset, alpha=0.5, min_shared_counts=20, n_top_genes=2000, n_pcs=50, n_neighbors=15):\n",
    "    # Load existing graph\n",
    "    graph = torch.load(f\"{dataset}/{dataset}_graph.pt\", weights_only=False)\n",
    "    print(f\"Loaded graph: {graph.x.shape[0]:,} nodes, {graph.edge_index.shape[1]:,} edges\")\n",
    "    \n",
    "    # Compute velocity\n",
    "    adata = compute_velocity(\n",
    "        adata,\n",
    "        min_shared_counts=min_shared_counts,\n",
    "        n_top_genes=n_top_genes,\n",
    "        n_pcs=n_pcs,\n",
    "        n_neighbors=n_neighbors\n",
    "    )\n",
    "    \n",
    "    # Reweight edges\n",
    "    graph = reweight_edges(graph, adata, alpha=alpha)\n",
    "    \n",
    "    # Save\n",
    "    save_velocity_data(adata, graph, dataset)\n",
    "    \n",
    "    return adata, graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc654881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: 53,268 nodes, 1,343,922 edges\n",
      "COMPUTING RNA VELOCITY\n",
      "\n",
      "Preprocessing for velocity!\n",
      "Filtered out 1179 genes that are detected 20 counts (shared).\n",
      "WARNING: Did not normalize X as it looks processed already. To enforce normalization, set `enforce=True`.\n",
      "Normalized count data: spliced, unspliced.\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scvelo/preprocessing/utils.py:705: DeprecationWarning: `log1p` is deprecated since scVelo v0.3.0 and will be removed in a future version. Please use `log1p` from `scanpy.pp` instead.\n",
      "  log1p(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logarithmized X.\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:00) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "\n",
      "Computing velocity!\n",
      "computing velocities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scvelo/tools/optimization.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  gamma[i] = np.linalg.pinv(A.T.dot(A)).dot(A.T.dot(y[:, i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:03) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "\n",
      "Building velocity graph!\n",
      "computing velocity graph (using 1/8 cores)\n",
      "    finished (0:00:31) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "\n",
      "Velocity computed!\n",
      "  Velocity (genes): (53268, 821)\n",
      "  Velocity (PCA):   (53268, 50)\n",
      "REWEIGHTING EDGES WITH VELOCITY\n",
      "--------------------------------------------------\n",
      "\n",
      "Alpha: 0.7\n",
      "Edges: 1,343,922\n",
      "Computing velocity alignment\n",
      "\n",
      "Alignment stats:\n",
      "  Range: [-0.820, 0.792]\n",
      "  Mean:  -0.063\n",
      "\n",
      "Edge weight stats:\n",
      "  Before: [0.127, 0.989]\n",
      "  After:  [-0.402, 0.829]\n",
      "\n",
      "Edges reweighted!\n",
      "\n",
      "SAVING NOW\n",
      "Saved: blood/blood_velocity_data.h5ad\n",
      "Saved: blood/blood_graph_velocity.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the adata (blood)\n",
    "adata = sc.read_h5ad(\"blood/blood_data.h5ad\")\n",
    "new_adata, new_graph = velocity_pipeline(adata, 'blood', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce63011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: 141,576 nodes, 3,294,318 edges\n",
      "COMPUTING RNA VELOCITY\n",
      "\n",
      "Preprocessing for velocity!\n",
      "Filtered out 1006 genes that are detected 20 counts (shared).\n",
      "WARNING: Did not normalize X as it looks processed already. To enforce normalization, set `enforce=True`.\n",
      "Normalized count data: spliced, unspliced.\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scvelo/preprocessing/utils.py:705: DeprecationWarning: `log1p` is deprecated since scVelo v0.3.0 and will be removed in a future version. Please use `log1p` from `scanpy.pp` instead.\n",
      "  log1p(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logarithmized X.\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:03) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "\n",
      "Computing velocity!\n",
      "computing velocities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scvelo/tools/optimization.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  gamma[i] = np.linalg.pinv(A.T.dot(A)).dot(A.T.dot(y[:, i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:13) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "\n",
      "Building velocity graph!\n",
      "computing velocity graph (using 1/8 cores)\n",
      "    finished (0:01:36) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "\n",
      "Velocity computed!\n",
      "  Velocity (genes): (141576, 994)\n",
      "  Velocity (PCA):   (141576, 50)\n",
      "REWEIGHTING EDGES WITH VELOCITY\n",
      "--------------------------------------------------\n",
      "\n",
      "Alpha: 0.7\n",
      "Edges: 3,294,318\n",
      "Computing velocity alignment\n",
      "\n",
      "Alignment stats:\n",
      "  Range: [-0.814, 0.780]\n",
      "  Mean:  -0.071\n",
      "\n",
      "Edge weight stats:\n",
      "  Before: [0.112, 0.983]\n",
      "  After:  [-0.402, 0.818]\n",
      "\n",
      "Edges reweighted!\n",
      "\n",
      "SAVING NOW\n",
      "Saved: neuron/neuron_velocity_data.h5ad\n",
      "Saved: neuron/neuron_graph_velocity.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the adata (neuron)\n",
    "adata = sc.read_h5ad(\"neuron/neuron_data.h5ad\")\n",
    "new_adata, new_graph = velocity_pipeline(adata, 'neuron', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3dd0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: 89,267 nodes, 1,961,242 edges\n",
      "COMPUTING RNA VELOCITY\n",
      "\n",
      "Preprocessing for velocity!\n",
      "Filtered out 864 genes that are detected 20 counts (shared).\n",
      "WARNING: Did not normalize X as it looks processed already. To enforce normalization, set `enforce=True`.\n",
      "Normalized count data: spliced, unspliced.\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`.\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scvelo/preprocessing/utils.py:705: DeprecationWarning: `log1p` is deprecated since scVelo v0.3.0 and will be removed in a future version. Please use `log1p` from `scanpy.pp` instead.\n",
      "  log1p(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logarithmized X.\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:02) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "\n",
      "Computing velocity!\n",
      "computing velocities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scvelo/tools/optimization.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  gamma[i] = np.linalg.pinv(A.T.dot(A)).dot(A.T.dot(y[:, i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:13) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "\n",
      "Building velocity graph!\n",
      "computing velocity graph (using 1/8 cores)\n",
      "    finished (0:01:25) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "\n",
      "Velocity computed!\n",
      "  Velocity (genes): (89267, 1136)\n",
      "  Velocity (PCA):   (89267, 50)\n",
      "REWEIGHTING EDGES WITH VELOCITY\n",
      "--------------------------------------------------\n",
      "\n",
      "Alpha: 0.7\n",
      "Edges: 1,961,242\n",
      "Computing velocity alignment\n",
      "\n",
      "Alignment stats:\n",
      "  Range: [-0.764, 0.783]\n",
      "  Mean:  0.029\n",
      "\n",
      "Edge weight stats:\n",
      "  Before: [0.223, 0.998]\n",
      "  After:  [-0.240, 0.840]\n",
      "\n",
      "Edges reweighted!\n",
      "\n",
      "SAVING NOW\n",
      "Saved: mouse/mouse_velocity_data.h5ad\n",
      "Saved: mouse/mouse_graph_velocity.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the adata (mouse)\n",
    "adata = sc.read_h5ad(\"mouse/mouse_data.h5ad\")\n",
    "new_adata, new_graph = velocity_pipeline(adata, 'mouse', alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
